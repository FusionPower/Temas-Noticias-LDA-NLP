{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos para Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook sólo enseño de dónde obtuve los datos para la visualización de Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector as mariadb\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    conn = mariadb.connect(\n",
    "      user=\"root\",\n",
    "      password=\"root\",\n",
    "      host=\"127.0.0.1\",\n",
    "      port=3306\n",
    "      )\n",
    "except mariadb.Error as e:\n",
    "    print(f\"Error connecting to MariaDB Platform: {e}\")\n",
    "    sys.exit(1)\n",
    "cursor=conn.cursor()\n",
    "cursor.execute(\"USE %s\"%\"noticias\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus(seleccion= [\"noticia\"], fecha=\"fecha\"):\n",
    "    seleccion=seleccion+[fecha]\n",
    "    cursor.execute(\"SELECT %s FROM notas WHERE fecha = %s\"%tuple(seleccion))\n",
    "    \n",
    "    resultados=cursor.fetchall()\n",
    "    return resultados\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=get_corpus([\"noticia\"],\"fecha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de lenguaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import spacy\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('spanish')\n",
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(texto):\n",
    "    doc = nlp(texto)\n",
    "    palabras = [t.orth_ for t in doc if not (t.is_punct | t.is_stop) and t.pos_ != 'PRON']\n",
    "    tokens = [t.lower() for t in palabras if len(t) > 3 and t.isalpha()]\n",
    "    raices = [stemmer.stem(token) for token in tokens]\n",
    "    return raices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = normalizar(\"Esto es lo que uno debería esperar después de que se pre-procesa un texto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deb', 'esper', 'text']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modificar_corpus(corpus):\n",
    "    corpus_modificado=[]\n",
    "    for noticia in corpus:\n",
    "        corpus_modificado.append(normalizar(noticia[0]))\n",
    "    return corpus_modificado\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CM=modificar_corpus(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aprendizaje No Supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import models\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import LdaModel, CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary=corpora.Dictionary(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(noticia) for noticia in CM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_topics=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=num_of_topics, id2word=dictionary, \n",
    "                                       passes=13, workers=2,\n",
    "                                      random_state=1,per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj=lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[row[0] for row in obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=[0,1,2,3,4,5,6,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    d={}\n",
    "    for element in result:\n",
    "        d[element[0]]=element[1]\n",
    "    insert=[0]*num_of_topics\n",
    "    \n",
    "    for i in d.keys():\n",
    "        insert[i]=d[i]\n",
    "    df=df.append(pd.Series(insert),ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tema Principal</th>\n",
       "      <th>Contribucion</th>\n",
       "      <th>Palabras Clave</th>\n",
       "      <th>Texto Normalizado</th>\n",
       "      <th>Texto Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[hollywood, comun, famos, sorprend, romanc, ju...</td>\n",
       "      <td>(En Hollywood es común que los famosos sorpren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[fri, nev, complic, segur, aument, consum, caf...</td>\n",
       "      <td>(Aunque el frío y las nevadas ha complicado a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[asad, escabech, herv, simplement, acompañ, pl...</td>\n",
       "      <td>(Asado, en escabeche,  hervido o simplemente a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[cab, dud, necesit, termin, seman, broch, darl...</td>\n",
       "      <td>(No cabe duda que necesitábamos terminar la se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[abuelit, vacun, mes, inic, pandemi, coronavir...</td>\n",
       "      <td>(¿Tus abuelitos ya se vacunaron contra el covi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>vacun, dosis, salud, millon, mayor, president,...</td>\n",
       "      <td>[promedi, person, acud, institut, nacional, el...</td>\n",
       "      <td>(En promedio, 120 mil personas acudieron al In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9219</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[pandemi, coronavirus, provoc, imagin, person,...</td>\n",
       "      <td>(La pandemia de coronavirus ha provocado que l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>años, mexican, equip, histori, libr, part, mex...</td>\n",
       "      <td>[anders, verjgang, jugador, profesional, famos...</td>\n",
       "      <td>(Anders Verjgang, el jugador profesional más f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[duqu, sussex, harry, megh, esper, hij, portav...</td>\n",
       "      <td>(Los duques de Sussex, Harry y Meghan, están e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9123</td>\n",
       "      <td>electr, mexic, aut, pes, usuari, servici, pais...</td>\n",
       "      <td>[miercol, usuari, servici, internet, izzi, rep...</td>\n",
       "      <td>(Este miércoles, usuarios del servicio de inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tema Principal  Contribucion  \\\n",
       "0             0.0        0.9948   \n",
       "1             0.0        0.6709   \n",
       "2             0.0        0.7906   \n",
       "3             0.0        0.9948   \n",
       "4             0.0        0.6684   \n",
       "5             2.0        0.8835   \n",
       "6             0.0        0.9219   \n",
       "7             5.0        0.9869   \n",
       "8             0.0        0.7271   \n",
       "9             4.0        0.9123   \n",
       "\n",
       "                                      Palabras Clave  \\\n",
       "0  fot, public, instagram, leer, compart, amor, c...   \n",
       "1  fot, public, instagram, leer, compart, amor, c...   \n",
       "2  fot, public, instagram, leer, compart, amor, c...   \n",
       "3  fot, public, instagram, leer, compart, amor, c...   \n",
       "4  fot, public, instagram, leer, compart, amor, c...   \n",
       "5  vacun, dosis, salud, millon, mayor, president,...   \n",
       "6  fot, public, instagram, leer, compart, amor, c...   \n",
       "7  años, mexican, equip, histori, libr, part, mex...   \n",
       "8  fot, public, instagram, leer, compart, amor, c...   \n",
       "9  electr, mexic, aut, pes, usuari, servici, pais...   \n",
       "\n",
       "                                   Texto Normalizado  \\\n",
       "0  [hollywood, comun, famos, sorprend, romanc, ju...   \n",
       "1  [fri, nev, complic, segur, aument, consum, caf...   \n",
       "2  [asad, escabech, herv, simplement, acompañ, pl...   \n",
       "3  [cab, dud, necesit, termin, seman, broch, darl...   \n",
       "4  [abuelit, vacun, mes, inic, pandemi, coronavir...   \n",
       "5  [promedi, person, acud, institut, nacional, el...   \n",
       "6  [pandemi, coronavirus, provoc, imagin, person,...   \n",
       "7  [anders, verjgang, jugador, profesional, famos...   \n",
       "8  [duqu, sussex, harry, megh, esper, hij, portav...   \n",
       "9  [miercol, usuari, servici, internet, izzi, rep...   \n",
       "\n",
       "                                      Texto Original  \n",
       "0  (En Hollywood es común que los famosos sorpren...  \n",
       "1  (Aunque el frío y las nevadas ha complicado a ...  \n",
       "2  (Asado, en escabeche,  hervido o simplemente a...  \n",
       "3  (No cabe duda que necesitábamos terminar la se...  \n",
       "4  (¿Tus abuelitos ya se vacunaron contra el covi...  \n",
       "5  (En promedio, 120 mil personas acudieron al In...  \n",
       "6  (La pandemia de coronavirus ha provocado que l...  \n",
       "7  (Anders Verjgang, el jugador profesional más f...  \n",
       "8  (Los duques de Sussex, Harry y Meghan, están e...  \n",
       "9  (Este miércoles, usuarios del servicio de inte...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_topic_DF(ldamodel, corpus, bow_texts,original,num_of_topics):\n",
    "\n",
    "    topic_df = pd.DataFrame()\n",
    "    \n",
    "    #extraemos las palabras clave por tema en un diccionario\n",
    "    topic_keywords={}\n",
    "    for topic_num in range(num_of_topics):\n",
    "        wp = ldamodel.show_topic(topic_num) #vector de tuplas de la forma (palabra, contribucion)\n",
    "        topic_keywords[topic_num] = \", \".join([word for word, prob in wp])\n",
    "    \n",
    "    \n",
    "    #para cada documento sacamos su tema dominante, su probabilidad y las palabras clave del tema\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0]\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        dominant=row[0]\n",
    "        topic_num=dominant[0]\n",
    "        prob_topic=dominant[1]\n",
    "        \n",
    "        topic_df = topic_df.append(pd.Series([int(topic_num), round(prob_topic,4), topic_keywords[topic_num]]), ignore_index=True)\n",
    "\n",
    "    \n",
    "    #añadimos los textos originales al DF\n",
    "    contents = pd.Series(bow_texts)\n",
    "    original = pd.Series(original)\n",
    "\n",
    "    topic_df = pd.concat([topic_df, contents,original], axis=1)\n",
    "    topic_df.columns = ['Tema Principal', 'Contribucion', 'Palabras Clave','Texto Normalizado', 'Texto Original']\n",
    "\n",
    "    return(topic_df)\n",
    "\n",
    "\n",
    "topic_df = get_topic_DF(lda_model, bow_corpus,CM,corpus,num_of_topics)\n",
    "\n",
    "topic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249694</td>\n",
       "      <td>0.079374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201852</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487062</td>\n",
       "      <td>0.119670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>0.737844</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>0.664313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>0.118673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2506 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2    3         4         5         6  \\\n",
       "0     0.994782  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "1     0.662904  0.000000  0.000000  0.0  0.249694  0.079374  0.000000   \n",
       "2     0.790555  0.000000  0.000000  0.0  0.000000  0.000000  0.201852   \n",
       "3     0.994815  0.000000  0.000000  0.0  0.000000  0.000000  0.000000   \n",
       "4     0.668393  0.000000  0.176966  0.0  0.000000  0.000000  0.150628   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2501  0.000000  0.487062  0.119670  0.0  0.000000  0.000000  0.000000   \n",
       "2502  0.737844  0.046874  0.000000  0.0  0.000000  0.083661  0.000000   \n",
       "2503  0.664313  0.000000  0.000000  0.0  0.253723  0.000000  0.000000   \n",
       "2504  0.118673  0.000000  0.025948  0.0  0.852150  0.000000  0.000000   \n",
       "2505  0.000000  0.000000  0.000000  0.0  0.000000  0.987114  0.000000   \n",
       "\n",
       "             7  \n",
       "0     0.000000  \n",
       "1     0.000000  \n",
       "2     0.000000  \n",
       "3     0.000000  \n",
       "4     0.000000  \n",
       "...        ...  \n",
       "2501  0.388859  \n",
       "2502  0.129799  \n",
       "2503  0.079156  \n",
       "2504  0.000000  \n",
       "2505  0.000000  \n",
       "\n",
       "[2506 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=([\"tema0\",\"tema1\",\"tema2\",\"tema3\",\"tema4\",\"tema5\",\"tema6\",\"tema7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.concat([df,topic_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tema0</th>\n",
       "      <th>tema1</th>\n",
       "      <th>tema2</th>\n",
       "      <th>tema3</th>\n",
       "      <th>tema4</th>\n",
       "      <th>tema5</th>\n",
       "      <th>tema6</th>\n",
       "      <th>tema7</th>\n",
       "      <th>Tema Principal</th>\n",
       "      <th>Contribucion</th>\n",
       "      <th>Palabras Clave</th>\n",
       "      <th>Texto Normalizado</th>\n",
       "      <th>Texto Original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.994782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[hollywood, comun, famos, sorprend, romanc, ju...</td>\n",
       "      <td>(En Hollywood es común que los famosos sorpren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662904</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.249694</td>\n",
       "      <td>0.079374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[fri, nev, complic, segur, aument, consum, caf...</td>\n",
       "      <td>(Aunque el frío y las nevadas ha complicado a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.790555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[asad, escabech, herv, simplement, acompañ, pl...</td>\n",
       "      <td>(Asado, en escabeche,  hervido o simplemente a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[cab, dud, necesit, termin, seman, broch, darl...</td>\n",
       "      <td>(No cabe duda que necesitábamos terminar la se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.668393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6684</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[abuelit, vacun, mes, inic, pandemi, coronavir...</td>\n",
       "      <td>(¿Tus abuelitos ya se vacunaron contra el covi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.487062</td>\n",
       "      <td>0.119670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.388859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>millon, cient, empres, xic, pes, ciud, servici...</td>\n",
       "      <td>[yucatan, otorg, credit, subsidi, incent, fisc...</td>\n",
       "      <td>(Yucatán.— Por el otorgamiento de créditos, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2502</th>\n",
       "      <td>0.737844</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7378</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[chef, libanes, deeb, harak, anunci, proxim, a...</td>\n",
       "      <td>(El chef libanés Deeb Harake anuncia la próxim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>0.664313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>fot, public, instagram, leer, compart, amor, c...</td>\n",
       "      <td>[contingent, millon, person, mund, recurr, pla...</td>\n",
       "      <td>(Debido a la contingencia por Covid-19 millone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>0.118673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>electr, mexic, aut, pes, usuari, servici, pais...</td>\n",
       "      <td>[model, celul, comenz, parec, fabric, busc, di...</td>\n",
       "      <td>(Cuando todos los modelos de celular comenzaro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2505</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>años, mexican, equip, histori, libr, part, mex...</td>\n",
       "      <td>[aleman, alexand, zverev, numer, mundial, avan...</td>\n",
       "      <td>(El alemán Alexander Zverev, número siete mund...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tema0     tema1     tema2  tema3     tema4     tema5     tema6  \\\n",
       "0     0.994782  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "1     0.662904  0.000000  0.000000    0.0  0.249694  0.079374  0.000000   \n",
       "2     0.790555  0.000000  0.000000    0.0  0.000000  0.000000  0.201852   \n",
       "3     0.994815  0.000000  0.000000    0.0  0.000000  0.000000  0.000000   \n",
       "4     0.668393  0.000000  0.176966    0.0  0.000000  0.000000  0.150628   \n",
       "...        ...       ...       ...    ...       ...       ...       ...   \n",
       "2501  0.000000  0.487062  0.119670    0.0  0.000000  0.000000  0.000000   \n",
       "2502  0.737844  0.046874  0.000000    0.0  0.000000  0.083661  0.000000   \n",
       "2503  0.664313  0.000000  0.000000    0.0  0.253723  0.000000  0.000000   \n",
       "2504  0.118673  0.000000  0.025948    0.0  0.852150  0.000000  0.000000   \n",
       "2505  0.000000  0.000000  0.000000    0.0  0.000000  0.987114  0.000000   \n",
       "\n",
       "         tema7  Tema Principal  Contribucion  \\\n",
       "0     0.000000             0.0        0.9948   \n",
       "1     0.000000             0.0        0.6709   \n",
       "2     0.000000             0.0        0.7906   \n",
       "3     0.000000             0.0        0.9948   \n",
       "4     0.000000             0.0        0.6684   \n",
       "...        ...             ...           ...   \n",
       "2501  0.388859             1.0        0.4863   \n",
       "2502  0.129799             0.0        0.7378   \n",
       "2503  0.079156             0.0        0.6643   \n",
       "2504  0.000000             4.0        0.8521   \n",
       "2505  0.000000             5.0        0.9871   \n",
       "\n",
       "                                         Palabras Clave  \\\n",
       "0     fot, public, instagram, leer, compart, amor, c...   \n",
       "1     fot, public, instagram, leer, compart, amor, c...   \n",
       "2     fot, public, instagram, leer, compart, amor, c...   \n",
       "3     fot, public, instagram, leer, compart, amor, c...   \n",
       "4     fot, public, instagram, leer, compart, amor, c...   \n",
       "...                                                 ...   \n",
       "2501  millon, cient, empres, xic, pes, ciud, servici...   \n",
       "2502  fot, public, instagram, leer, compart, amor, c...   \n",
       "2503  fot, public, instagram, leer, compart, amor, c...   \n",
       "2504  electr, mexic, aut, pes, usuari, servici, pais...   \n",
       "2505  años, mexican, equip, histori, libr, part, mex...   \n",
       "\n",
       "                                      Texto Normalizado  \\\n",
       "0     [hollywood, comun, famos, sorprend, romanc, ju...   \n",
       "1     [fri, nev, complic, segur, aument, consum, caf...   \n",
       "2     [asad, escabech, herv, simplement, acompañ, pl...   \n",
       "3     [cab, dud, necesit, termin, seman, broch, darl...   \n",
       "4     [abuelit, vacun, mes, inic, pandemi, coronavir...   \n",
       "...                                                 ...   \n",
       "2501  [yucatan, otorg, credit, subsidi, incent, fisc...   \n",
       "2502  [chef, libanes, deeb, harak, anunci, proxim, a...   \n",
       "2503  [contingent, millon, person, mund, recurr, pla...   \n",
       "2504  [model, celul, comenz, parec, fabric, busc, di...   \n",
       "2505  [aleman, alexand, zverev, numer, mundial, avan...   \n",
       "\n",
       "                                         Texto Original  \n",
       "0     (En Hollywood es común que los famosos sorpren...  \n",
       "1     (Aunque el frío y las nevadas ha complicado a ...  \n",
       "2     (Asado, en escabeche,  hervido o simplemente a...  \n",
       "3     (No cabe duda que necesitábamos terminar la se...  \n",
       "4     (¿Tus abuelitos ya se vacunaron contra el covi...  \n",
       "...                                                 ...  \n",
       "2501  (Yucatán.— Por el otorgamiento de créditos, su...  \n",
       "2502  (El chef libanés Deeb Harake anuncia la próxim...  \n",
       "2503  (Debido a la contingencia por Covid-19 millone...  \n",
       "2504  (Cuando todos los modelos de celular comenzaro...  \n",
       "2505  (El alemán Alexander Zverev, número siete mund...  \n",
       "\n",
       "[2506 rows x 13 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
